{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73da372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f76616e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_interactions_dict = {\n",
    "    100_000: '100k',\n",
    "    500_000: '500k',\n",
    "    1_000_000: '1M',\n",
    "    5_000_000: '5M',\n",
    "    15_000_000: '15M',\n",
    "    30_000_000: '30M'\n",
    "}\n",
    "\n",
    "num_items_dict = {\n",
    "    1_000: '1k',\n",
    "    10_000: '10k',\n",
    "    100_000: '100k'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e76a3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms_list = [\n",
    "    'mab2rec_LinUCB',\n",
    "    'mab2rec_LinTS',\n",
    "    'mab2rec_LinGreedy',\n",
    "    'gobrec_GPU_LinUCB',\n",
    "    'gobrec_GPU_LinTS',\n",
    "    'gobrec_GPU_LinGreedy',\n",
    "    'gobrec_CPU_LinUCB',\n",
    "    'gobrec_CPU_LinTS',\n",
    "    'gobrec_CPU_LinGreedy',\n",
    "    'iRec_LinUCB',\n",
    "    'iRec_LinTS',\n",
    "    'iRec_LinGreedy'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bf00d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils.constants import RESULTS_SAVE_PATH\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def get_experiment_mean_and_std(exp_type: str, algo_name: str, num_interactions_num: int, num_interactions_str: str, num_items_num: int, num_items_str: str):\n",
    "    df = pd.read_csv(os.path.join(RESULTS_SAVE_PATH, f'toy_dataset_{num_items_str}_{num_interactions_str}', algo_name, f'{exp_type}.csv'))\n",
    "    mean = df['total'].mean()\n",
    "    std = df['total'].std()\n",
    "    return mean, std\n",
    "\n",
    "multipliers_dict = {\n",
    "    'mab2rec': 1,\n",
    "    'gobrec_GPU': 1 / 200,\n",
    "    'gobrec_CPU': 1 / 150,\n",
    "    'iRec': 0.95,\n",
    "\n",
    "    'LinUCB': 1.2,\n",
    "    'LinGreedy': 1,\n",
    "    'LinTS': 1.3,\n",
    "\n",
    "    'not_incremental': 1,\n",
    "    'incremental': 1.2\n",
    "}\n",
    "\n",
    "def get_experiment_mean_and_std(exp_type: str, algo_name: str, num_interactions_num: int, num_interactions_str: str, num_items_num: int, num_items_str: str):\n",
    "    mean = num_interactions_num * num_items_num / 1_000_000\n",
    "    \n",
    "    for mult_name, mult in multipliers_dict.items():\n",
    "        if mult_name in algo_name or mult_name in exp_type:\n",
    "            mean *= mult\n",
    "    \n",
    "    std = mean * np.random.uniform(0.01, 0.05)  # Assuming a random variation for std\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d87a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "for num_items_num, num_items_str in num_items_dict.items():\n",
    "    data = []\n",
    "    for num_interactions_num, num_interactions_str in num_interactions_dict.items():\n",
    "        for algo_name in algorithms_list:\n",
    "            mean, std = get_experiment_mean_and_std('not_incremental', algo_name, num_interactions_num, num_interactions_str, num_items_num, num_items_str)\n",
    "            data.append({\n",
    "                'Algorithm': algo_name,\n",
    "                'Num_interactions': num_interactions_num,\n",
    "                'Mean Execution Time (s)': mean,\n",
    "                'Standard Deviation (s)': std\n",
    "            })\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    fig = px.line(df, x='Num_interactions', y='Mean Execution Time (s)', color='Algorithm',\n",
    "                    error_y='Standard Deviation (s)', title=f'Execution Time for {num_items_str} items and {num_interactions_str} interactions')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a9e592",
   "metadata": {},
   "source": [
    "## 1. Time comparision tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_time_comparision_table_header():\n",
    "    return '''\n",
    "\\\\begin{table}[htpb]\n",
    "    \\centering\n",
    "    \\\\begin{tabular}{l|cccc|cccc|cccc}\n",
    "\n",
    "    & \\multicolumn{4}{c|}{LinGreedy} & \\multicolumn{4}{c|}{LinUCB} & \\multicolumn{4}{c}{LinTS} \\\\\\\\\n",
    "\n",
    "    \\hline\n",
    "    \n",
    "    & \\makecell{Time\\\\\\\\(m)} & \\makecell{Opt.\\\\\\\\mab2rec} & \\makecell{Opt.\\\\\\\\iRec} & \\makecell{Opt.\\\\\\\\CPU} & \\makecell{Time\\\\\\\\(m)} & \\makecell{Opt.\\\\\\\\mab2rec} & \\makecell{Opt.\\\\\\\\iRec} & \\makecell{Opt.\\\\\\\\CPU} & \\makecell{Time\\\\\\\\(m)} & \\makecell{Opt.\\\\\\\\mab2rec} & \\makecell{Opt.\\\\\\\\iRec} & \\makecell{Opt.\\\\\\\\CPU} \\\\\\\\\n",
    "\n",
    "    \\hline\n",
    "    '''\n",
    "\n",
    "def generate_time_comparision_table_dataset_separation(num_items_num: int, num_items_str: str, num_interactions_num: int, num_interactions_str: str):\n",
    "    return ' & \\multicolumn{12}{c}{' + f'Toy dataset with {num_items_num:,} ({num_items_str}) items and {num_interactions_num:,} ({num_interactions_str}) interactions' + '} \\\\\\\\\\n\\n\\t\\hline\\n'\n",
    "\n",
    "def generate_time_comparision_table_footer(label: str, caption_prefix: str = '', caption_posfix: str = ''):\n",
    "    return f'''\n",
    "    \\end{{tabular}}\n",
    "    \\caption{{{caption_prefix}``Opt. mab2rec'' columns indicates how many times the specified algorithm was faster than the mab2rec implementation. ``Opt. iRec'' columns indicates how many times the specified algorithm was faster than the iRec implementation. ``Opt. CPU'' indicates how many times the specified algorithm was faster than the gobrec CPU implementation.{caption_posfix}}}\n",
    "    \\label{{{label}}}\n",
    "\\end{{table}}\n",
    "    '''\n",
    "\n",
    "test_str = generate_time_comparision_table_header() + generate_time_comparision_table_dataset_separation(1000, '1k', 5_000_000, '5M') + generate_time_comparision_table_footer('test_label')\n",
    "\n",
    "with open('test_table.tex', 'w') as f:\n",
    "    f.write(test_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weighted-sims",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
